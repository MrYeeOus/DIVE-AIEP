{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGvSN1txYKX4",
    "outputId": "5a7c1064-1b1b-4701-f68b-b7b04b8fda47"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install accelerate\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPAa0Bn-YqBo",
    "outputId": "d9e42be9-02be-4901-a9b1-ce16f99c4f54"
   },
   "outputs": [],
   "source": [
    "# GOOGLE COLAB\n",
    "# Upload the mergedJson.json zip file, to preserve contents\n",
    "!unzip content/mergedJson.zip\n",
    "!sha1sum content/mergedJson.json\n",
    "# Should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XlGos1fYrH7"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/mergedJson.json\", \"rb\") as jsonl_file:\n",
    "    data_list = json.load(jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL\n",
    "with open(\"./content/mergedJson.json\", \"rb\") as jsonl_file:\n",
    "    data_list = json.load(jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "dLUVlWGibJo-",
    "outputId": "a8ca6d7e-3e20-4dd2-e967-8fc562d05ffe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list.keys()\n",
    "len(data_list[\"GENERATED_DESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1197"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list[\"GENERATED_DATA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "-T_NqnfYbUzo",
    "outputId": "d7efd516-1b7d-47f7-f15c-ce562a5e704a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "\n",
    "del data_list[\"GENERATED_DATA\"][len(data_list[\"GENERATED_DESCRIPTION\"]):]\n",
    "\n",
    "len(data_list[\"GENERATED_DATA\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENERATED_DESCRIPTION</th>\n",
       "      <th>GENERATED_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'location': '&lt;Vector (0.0000, 0.0000, 9.0000)...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"Obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'location': '&lt;Vector (-3.0000, 4.5000, 0.5000...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'location': '&lt;Vector (-1.0000, 5.5000, 0.5000...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"Obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'location': '&lt;Vector (4.0000, -5.5000, 0.5000...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"Obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'location': '&lt;Vector (0.0000, 4.5000, 0.5000)...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"Obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>{'location': '&lt;Vector (-1.5000, -3.5000, 0.500...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>{'location': '&lt;Vector (3.5000, -2.5000, 0.5000...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"Obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>{'location': '&lt;Vector (2.5000, 7.5000, 0.5000)...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"Obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>{'location': '&lt;Vector (0.5000, 6.5000, 0.5000)...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"Obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>{'location': '&lt;Vector (1.5000, -1.5000, 0.5000...</td>\n",
       "      <td>b'&lt;library_geometries&gt;\\n    &lt;geometry id=\"Obje...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1188 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  GENERATED_DESCRIPTION  \\\n",
       "0     {'location': '<Vector (0.0000, 0.0000, 9.0000)...   \n",
       "1     {'location': '<Vector (-3.0000, 4.5000, 0.5000...   \n",
       "2     {'location': '<Vector (-1.0000, 5.5000, 0.5000...   \n",
       "3     {'location': '<Vector (4.0000, -5.5000, 0.5000...   \n",
       "4     {'location': '<Vector (0.0000, 4.5000, 0.5000)...   \n",
       "...                                                 ...   \n",
       "1183  {'location': '<Vector (-1.5000, -3.5000, 0.500...   \n",
       "1184  {'location': '<Vector (3.5000, -2.5000, 0.5000...   \n",
       "1185  {'location': '<Vector (2.5000, 7.5000, 0.5000)...   \n",
       "1186  {'location': '<Vector (0.5000, 6.5000, 0.5000)...   \n",
       "1187  {'location': '<Vector (1.5000, -1.5000, 0.5000...   \n",
       "\n",
       "                                         GENERATED_DATA  \n",
       "0     b'<library_geometries>\\n    <geometry id=\"Obje...  \n",
       "1     b'<library_geometries>\\n    <geometry id=\"room...  \n",
       "2     b'<library_geometries>\\n    <geometry id=\"Obje...  \n",
       "3     b'<library_geometries>\\n    <geometry id=\"Obje...  \n",
       "4     b'<library_geometries>\\n    <geometry id=\"Obje...  \n",
       "...                                                 ...  \n",
       "1183  b'<library_geometries>\\n    <geometry id=\"room...  \n",
       "1184  b'<library_geometries>\\n    <geometry id=\"Obje...  \n",
       "1185  b'<library_geometries>\\n    <geometry id=\"Obje...  \n",
       "1186  b'<library_geometries>\\n    <geometry id=\"Obje...  \n",
       "1187  b'<library_geometries>\\n    <geometry id=\"Obje...  \n",
       "\n",
       "[1188 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data_list, columns=[\"GENERATED_DESCRIPTION\", \"GENERATED_DATA\"])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7XsHp_6JYtYK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['GENERATED_DESCRIPTION', 'GENERATED_DATA'],\n",
      "        num_rows: 600\n",
      "    })\n",
      "    validate: Dataset({\n",
      "        features: ['GENERATED_DESCRIPTION', 'GENERATED_DATA'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['GENERATED_DESCRIPTION', 'GENERATED_DATA'],\n",
      "        num_rows: 388\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataframe_train = Dataset.from_pandas(dataframe[:600])\n",
    "dataframe_validate = Dataset.from_pandas(dataframe[600:800])\n",
    "dataframe_test = Dataset.from_pandas(dataframe[800:])\n",
    "\n",
    "dataset3 = DatasetDict({\"train\": dataframe_train, \"validate\": dataframe_validate, \"test\": dataframe_test})\n",
    "print(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6ikLNgJZYugL"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 512\n",
    "\n",
    "# task_prefix = \"json2dae: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RTVdCIMEYvqb"
   },
   "outputs": [],
   "source": [
    "output_sequences = dataset3[\"train\"][\"GENERATED_DATA\"]\n",
    "output_sequences = [str(seq) for seq in output_sequences]\n",
    "labels = tokenizer(\n",
    "    output_sequences,\n",
    "    max_length = max_target_length,\n",
    "    padding = \"max_length\",\n",
    "    truncation = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "sjpUUQpjYwsF"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad54de5bca84648adc5e394e631da70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7426497da0f4f7bb56da04531d44ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a12039f98eb4831869bd7075185d810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['GENERATED_DESCRIPTION', 'GENERATED_DATA', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['GENERATED_DESCRIPTION', 'GENERATED_DATA', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['GENERATED_DESCRIPTION', 'GENERATED_DATA', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 388\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(inputData):\n",
    "    input_sequences = inputData[\"GENERATED_DESCRIPTION\"]\n",
    "    input_sequences = [str(seq) for seq in input_sequences]\n",
    "\n",
    "    output_sequences = inputData[\"GENERATED_DATA\"]\n",
    "    output_sequences = [str(seq) for seq in output_sequences]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        input_sequences,\n",
    "        max_length = max_source_length,\n",
    "        padding = \"max_length\",\n",
    "        truncation = True\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        output_sequences,\n",
    "        max_length = max_target_length,\n",
    "        padding = \"max_length\",\n",
    "        truncation = True\n",
    "    )\n",
    "\n",
    "    # Replace padding tokens with -100 so they are\n",
    "    # ignored by CrossEntropyLoss thing\n",
    "    #labels_with_ignore_index = []\n",
    "    #for sample in labels:\n",
    "    #    sample = [label if label != 0 else -100 for label in sample]\n",
    "    #    labels_with_ignore_index.append(sample)\n",
    "\n",
    "    labels_with_ignore_index = []\n",
    "    for label_sample in labels[\"input_ids\"]:\n",
    "        label_sample = [label if label != 0 else -100 for label in label_sample]\n",
    "        labels_with_ignore_index.append(label_sample)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels_with_ignore_index\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "\n",
    "mapped_dataset = dataset3.map(preprocess_data, batched=True, batch_size=2)\n",
    "mapped_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "bg1aTScvY4jG",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 70,\n",
       " 11,\n",
       " 32,\n",
       " 12083,\n",
       " 67,\n",
       " 10049,\n",
       " 9407,\n",
       " 5333,\n",
       " 82,\n",
       " 565,\n",
       " 411,\n",
       " 14330,\n",
       " 612,\n",
       " 1546,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 6,\n",
       " 508,\n",
       " 1546,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 6,\n",
       " 5333,\n",
       " 82,\n",
       " 1377,\n",
       " 411,\n",
       " 15557,\n",
       " 5333,\n",
       " 82,\n",
       " 3639,\n",
       " 411,\n",
       " 3168,\n",
       " 612,\n",
       " 1546,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 17,\n",
       " 12388,\n",
       " 6,\n",
       " 5333,\n",
       " 82,\n",
       " 1850,\n",
       " 411,\n",
       " 5659,\n",
       " 67,\n",
       " 1126,\n",
       " 612,\n",
       " 1546,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 17,\n",
       " 12388,\n",
       " 17,\n",
       " 1126,\n",
       " 6,\n",
       " 1056,\n",
       " 1546,\n",
       " 3247,\n",
       " 6441,\n",
       " 17,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 300,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 1757,\n",
       " 5659,\n",
       " 67,\n",
       " 1126,\n",
       " 5333,\n",
       " 82,\n",
       " 1850,\n",
       " 411,\n",
       " 28012,\n",
       " 82,\n",
       " 2161,\n",
       " 67,\n",
       " 6054,\n",
       " 5333,\n",
       " 82,\n",
       " 5411,\n",
       " 411,\n",
       " 3860,\n",
       " 280,\n",
       " 1084,\n",
       " 1546,\n",
       " 7,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 17,\n",
       " 12388,\n",
       " 17,\n",
       " 1126,\n",
       " 6,\n",
       " 1056,\n",
       " 1546,\n",
       " 28,\n",
       " 6,\n",
       " 11084,\n",
       " 1546,\n",
       " 23,\n",
       " 6,\n",
       " 5333,\n",
       " 82,\n",
       " 2868,\n",
       " 411,\n",
       " 891,\n",
       " 508,\n",
       " 1546,\n",
       " 60,\n",
       " 6,\n",
       " 618,\n",
       " 1546,\n",
       " 5659,\n",
       " 6,\n",
       " 342,\n",
       " 5333,\n",
       " 82,\n",
       " 2868,\n",
       " 411,\n",
       " 891,\n",
       " 508,\n",
       " 1546,\n",
       " 61,\n",
       " 6,\n",
       " 618,\n",
       " 1546,\n",
       " 5659,\n",
       " 6,\n",
       " 342,\n",
       " 5333,\n",
       " 82,\n",
       " 2868,\n",
       " 411,\n",
       " 891,\n",
       " 508,\n",
       " 1546,\n",
       " 62,\n",
       " 6,\n",
       " 618,\n",
       " 1546,\n",
       " 5659,\n",
       " 6,\n",
       " 342,\n",
       " 5333,\n",
       " 82,\n",
       " 5411,\n",
       " 7765,\n",
       " 3860,\n",
       " 280,\n",
       " 5333,\n",
       " 82,\n",
       " 1850,\n",
       " 7765,\n",
       " 28012,\n",
       " 82,\n",
       " 2161,\n",
       " 67,\n",
       " 6054,\n",
       " 5333,\n",
       " 82,\n",
       " 3639,\n",
       " 7765,\n",
       " 3168,\n",
       " 5333,\n",
       " 82,\n",
       " 3639,\n",
       " 411,\n",
       " 3168,\n",
       " 612,\n",
       " 1546,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 17,\n",
       " 7959,\n",
       " 1031,\n",
       " 6,\n",
       " 5333,\n",
       " 82,\n",
       " 1850,\n",
       " 411,\n",
       " 5659,\n",
       " 67,\n",
       " 1126,\n",
       " 612,\n",
       " 1546,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 17,\n",
       " 7959,\n",
       " 1031,\n",
       " 17,\n",
       " 1126,\n",
       " 6,\n",
       " 1056,\n",
       " 1546,\n",
       " 2643,\n",
       " 6441,\n",
       " 17,\n",
       " 21,\n",
       " 374,\n",
       " 374,\n",
       " 374,\n",
       " 404,\n",
       " 374,\n",
       " 404,\n",
       " 374,\n",
       " 374,\n",
       " 374,\n",
       " 300,\n",
       " 21,\n",
       " 374,\n",
       " 374,\n",
       " 374,\n",
       " 300,\n",
       " 21,\n",
       " 374,\n",
       " 374,\n",
       " 404,\n",
       " 1757,\n",
       " 5659,\n",
       " 67,\n",
       " 1126,\n",
       " 5333,\n",
       " 82,\n",
       " 1850,\n",
       " 411,\n",
       " 28012,\n",
       " 82,\n",
       " 2161,\n",
       " 67,\n",
       " 6054,\n",
       " 5333,\n",
       " 82,\n",
       " 5411,\n",
       " 411,\n",
       " 3860,\n",
       " 280,\n",
       " 1084,\n",
       " 1546,\n",
       " 7,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 17,\n",
       " 7959,\n",
       " 1031,\n",
       " 17,\n",
       " 1126,\n",
       " 6,\n",
       " 1056,\n",
       " 1546,\n",
       " 26,\n",
       " 6,\n",
       " 11084,\n",
       " 1546,\n",
       " 23,\n",
       " 6,\n",
       " 5333,\n",
       " 82,\n",
       " 2868,\n",
       " 411,\n",
       " 891,\n",
       " 508,\n",
       " 1546,\n",
       " 60,\n",
       " 6,\n",
       " 618,\n",
       " 1546,\n",
       " 5659,\n",
       " 6,\n",
       " 342,\n",
       " 5333,\n",
       " 82,\n",
       " 2868,\n",
       " 411,\n",
       " 891,\n",
       " 508,\n",
       " 1546,\n",
       " 61,\n",
       " 6,\n",
       " 618,\n",
       " 1546,\n",
       " 5659,\n",
       " 6,\n",
       " 342,\n",
       " 5333,\n",
       " 82,\n",
       " 2868,\n",
       " 411,\n",
       " 891,\n",
       " 508,\n",
       " 1546,\n",
       " 62,\n",
       " 6,\n",
       " 618,\n",
       " 1546,\n",
       " 5659,\n",
       " 6,\n",
       " 342,\n",
       " 5333,\n",
       " 82,\n",
       " 5411,\n",
       " 7765,\n",
       " 3860,\n",
       " 280,\n",
       " 5333,\n",
       " 82,\n",
       " 1850,\n",
       " 7765,\n",
       " 28012,\n",
       " 82,\n",
       " 2161,\n",
       " 67,\n",
       " 6054,\n",
       " 5333,\n",
       " 82,\n",
       " 3639,\n",
       " 7765,\n",
       " 3168,\n",
       " 5333,\n",
       " 82,\n",
       " 3639,\n",
       " 411,\n",
       " 3168,\n",
       " 612,\n",
       " 1546,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 17,\n",
       " 1458,\n",
       " 17,\n",
       " 20,\n",
       " 6,\n",
       " 5333,\n",
       " 82,\n",
       " 1850,\n",
       " 411,\n",
       " 5659,\n",
       " 67,\n",
       " 1126,\n",
       " 612,\n",
       " 1546,\n",
       " 921,\n",
       " 67,\n",
       " 23,\n",
       " 17,\n",
       " 15557,\n",
       " 17,\n",
       " 1458,\n",
       " 17,\n",
       " 20,\n",
       " 17,\n",
       " 1126,\n",
       " 6,\n",
       " 1056,\n",
       " 1546,\n",
       " 9060,\n",
       " 6441,\n",
       " 20,\n",
       " 18,\n",
       " 26,\n",
       " 2947,\n",
       " 374,\n",
       " 374,\n",
       " 18,\n",
       " 23,\n",
       " 5877,\n",
       " 374,\n",
       " 18,\n",
       " 2947,\n",
       " 374,\n",
       " 18,\n",
       " 23,\n",
       " 5877,\n",
       " 374,\n",
       " 374,\n",
       " 18,\n",
       " 26,\n",
       " 2947,\n",
       " 374,\n",
       " 18,\n",
       " 2947,\n",
       " 374,\n",
       " 18,\n",
       " 23,\n",
       " 5877,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 23,\n",
       " 5877,\n",
       " 374,\n",
       " 18,\n",
       " 2947,\n",
       " 374,\n",
       " 18,\n",
       " 26,\n",
       " 2947,\n",
       " 374,\n",
       " 18,\n",
       " 25,\n",
       " 374,\n",
       " 18,\n",
       " 23,\n",
       " 5877,\n",
       " 2]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_dataset[\"test\"][\"labels\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jY4lHiJzY538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: 6May24_v1_m512_M512_S1188_mapped_dataset.pkl (deflated 98%)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('6May24_v1_m512_M512_S1188_mapped_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(mapped_dataset, f)\n",
    "\n",
    "!zip 6May24_v1_m512_M512_S1188_mapped_dataset.pkl.zip 6May24_v1_m512_M512_S1188_mapped_dataset.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTSIAgtyY7bs"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "mapped_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "train_dataloader = DataLoader(mapped_dataset[\"train\"], shuffle=True, batch_size=2)\n",
    "valid_dataloader = DataLoader(mapped_dataset[\"validate\"], batch_size=2)\n",
    "test_dataloader = DataLoader(mapped_dataset[\"test\"], batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXINda3LY_9j"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-small')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1toKBZBjZAuK"
   },
   "outputs": [],
   "source": [
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqTMcteDZCXP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer, DefaultDataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0kSowxUZDzD"
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "mapped_train = mapped_dataset[\"train\"]\n",
    "mapped_validate = mapped_dataset[\"validate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6QFJWV8ZEp7"
   },
   "outputs": [],
   "source": [
    "dataset_training = mapped_train.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=2,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "dataset_validation = mapped_validate.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=2,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIetXwncZFm8"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"/\",\n",
    "    num_train_epochs = 3,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    save_steps = 400,\n",
    "    save_total_limit = 2,\n",
    "    eval_steps = 100,\n",
    "    eval_strategy = \"steps\",\n",
    "    fp16 = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = mapped_dataset[\"train\"],\n",
    "    eval_dataset = mapped_dataset[\"validate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxfjsaD3ZGuk"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuXYP6WtZHtZ"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"29Apr24_v1\")\n",
    "!zip -r 29Apr24_model_v1.zip 29Apr24_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrXPpRYabyUI",
    "outputId": "4cbd6cb9-6df9-4631-b964-8d97081fca33"
   },
   "outputs": [],
   "source": [
    "# @title Testing\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "model_path = \"29Apr24_v1\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "\n",
    "def translator(model, tokenizer):\n",
    "  inputs = \"\"\"\n",
    "  {\n",
    "    \"large_cube_location\": \"<Vector (0.0000, 0.0000, 10.5000)>\",\n",
    "    \"large_cube_size\": \"<Vector (11.0000, 24.0000, 21.0000)>\",\n",
    "    \"Object0_location\": \"<Vector (-0.5000, 5.0000, 0.5000)>\",\n",
    "    \"Object0_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object1_location\": \"<Vector (-3.5000, -4.0000, 0.5000)>\",\n",
    "    \"Object1_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object2_location\": \"<Vector (1.5000, -3.0000, 0.5000)>\",\n",
    "    \"Object2_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object3_location\": \"<Vector (-0.5000, 8.0000, 0.5000)>\",\n",
    "    \"Object3_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object4_location\": \"<Vector (4.5000, -4.0000, 0.5000)>\",\n",
    "    \"Object4_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object5_location\": \"<Vector (2.5000, -3.0000, 0.5000)>\",\n",
    "    \"Object5_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object6_location\": \"<Vector (-0.5000, -8.0000, 0.5000)>\",\n",
    "    \"Object6_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object7_location\": \"<Vector (2.5000, -6.0000, 0.5000)>\",\n",
    "    \"Object7_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object8_location\": \"<Vector (2.5000, 3.0000, 0.5000)>\",\n",
    "    \"Object8_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object9_location\": \"<Vector (-3.5000, 3.0000, 0.5000)>\",\n",
    "    \"Object9_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object10_location\": \"<Vector (1.5000, -11.0000, 0.5000)>\",\n",
    "    \"Object10_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object11_location\": \"<Vector (-1.5000, 0.0000, 0.5000)>\",\n",
    "    \"Object11_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\",\n",
    "    \"Object12_location\": \"<Vector (2.5000, 11.0000, 0.5000)>\",\n",
    "    \"Object12_size\": \"<Vector (1.0000, 1.0000, 1.0000)>\"\n",
    "  }\n",
    "  \"\"\"\n",
    "  input_tokens = tokenizer.encode(\n",
    "      inputs,\n",
    "      return_tensors = \"pt\",\n",
    "      max_length = 512,\n",
    "      truncation = True\n",
    "  )\n",
    "\n",
    "  corrected_ids = model.generate(\n",
    "      input_tokens,\n",
    "      max_length = 1024\n",
    "  )\n",
    "\n",
    "  corrected_text = tokenizer.decode(corrected_ids[0], skip_special_tokens = True)\n",
    "  return corrected_text\n",
    "\n",
    "tokenstuff = translator(model, tokenizer)\n",
    "print(tokenstuff)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
